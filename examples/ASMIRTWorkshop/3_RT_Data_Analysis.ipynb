{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Radiotherapy Image Data Analysis\n",
    "\n",
    "This notebook is part of the **Radiotherapy image data analysis using Python** Workshop at ASMIRT 2023 in Sydney, Australia.\n",
    "\n",
    "In this part you will learn about how we can convert and analyse RT DICOM data:\n",
    "- Convert a collection of DICOM data into NIfTI format\n",
    "- Automatically select the data objects we want to analyse for each patient\n",
    "- Compute DVHs and extract dose metrics\n",
    "- Box plots of dose metrics\n",
    "\n",
    "## Import libraries and download some sample data\n",
    "\n",
    "First we will import some libraries that we will need and download some DICOM data which we can use\n",
    "for these examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from pydicer import PyDicer\n",
    "    from pydicer.utils import read_converted_data\n",
    "except:\n",
    "    ! pip install git+https://github.com/AustralianCancerDataNetwork/pydicer.git\n",
    "    from pydicer import PyDicer\n",
    "    from pydicer.utils import read_converted_data\n",
    "\n",
    "import tempfile\n",
    "import zipfile\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "\n",
    "dicom_zip_url = \"https://unsw-my.sharepoint.com/:u:/g/personal/z3523015_ad_unsw_edu_au/EfuOALdQEHtFph3EzdpmbOUBx3-kPcLGpuQI2sML7vje-g?download=1\"\n",
    "dicom_directory = \"dicom\"\n",
    "\n",
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    temp_file = Path(temp_dir).joinpath(\"tmp.zip\")\n",
    "        \n",
    "    data = requests.get(dicom_zip_url)\n",
    "    with open(temp_file, 'wb')as out_file:\n",
    "        out_file.write(data.content)\n",
    "        \n",
    "    with zipfile.ZipFile(temp_file, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(dicom_directory)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup PyDicer tool\n",
    "\n",
    "Create a PyDicer object, telling it where to store our data to analyse. We also add an input\n",
    "folder which contains the DICOM data we want to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a directory in which to store our converted data\n",
    "working_directory = Path(\"./working\")\n",
    "\n",
    "# Create a PyDicer object (called pyd) for us to work with\n",
    "pyd = PyDicer(working_directory)\n",
    "\n",
    "# Set some configuration to turn off generating NRRD files (makes conversion run faster)\n",
    "pyd.config.set_config(\"generate_nrrd\", False)\n",
    "\n",
    "# Add the directory containing downloaded DICOM as an input path\n",
    "pyd.add_input(dicom_directory)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data\n",
    "\n",
    "Next we call the preprocess function, this reads through our folder of DICOMs and tracks the\n",
    "files available ready for conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyd.preprocess()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert data\n",
    "\n",
    "The convert function converts the DICOM data into NIfTI. Check out the `working` folder to see the\n",
    "files appear as they are converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyd.convert.convert()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise data\n",
    "\n",
    "PyDicer can create visualisations of the images, structures and dose which it converts. Check those\n",
    "out in the `working` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyd.visualise.visualise()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset\n",
    "\n",
    "Now that our data is converted, we are almost ready to start analysing it. But first, we want to\n",
    "prepare a clean dataset since some of our data has multiple structure sets and multiple dose grids.\n",
    "\n",
    "We can use the `read_converted_data` function from the PyDicer library to fetch a Pandas DataFrame\n",
    "containing all data converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = read_converted_data(working_directory)\n",
    "df_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll use the PyDicer preparation module to select the latest RTDOSE for each patient, along\n",
    "with the linked datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dataset = \"clean\"\n",
    "pyd.dataset.prepare(clean_dataset, \"rt_latest_dose\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's read the converted data in our clean dataset. We should now have exactly one CT,\n",
    "RTSTRUCT, RTPLAN and RTDOSE per patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = read_converted_data(working_directory, dataset_name=clean_dataset)\n",
    "df_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Dose Volume Histogram (DVH)\n",
    "\n",
    "Before we can extract dose metrics, we first need to compute the DVHs on our cleaned up dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyd.analyse.compute_dvh(dataset_name=clean_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Dose Metrics\n",
    "\n",
    "And then we can extract some common dose metrics.\n",
    "\n",
    "> Tip: The `compute_dose_metrics` accepts paramters `d_point`, `v_point`, `d_cc_point` which accept lists\n",
    "of values to compute dose metrics for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dose_metrics = pyd.analyse.compute_dose_metrics(d_point=[50,95], d_cc_point=[2], dataset_name=clean_dataset)\n",
    "df_dose_metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up dose metrics\n",
    "\n",
    "This has produced the dose metrics for all structures. We only want to analyse a subset, so here's\n",
    "some code which will filter these out and standardise the label names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_names = {\n",
    "    \"PTV\": [\"PTV_57_Gy\", \"PTV57\", \"ptv57\"],\n",
    "    \"CTV\": [\"CTV_57_Gy\", \"CTV_57\", \"ctv_57\"],\n",
    "    \"Brainstem\": [],\n",
    "    \"SpinalCord\": [\"Cord\", \"\"],\n",
    "    \"Lt_Parotid\": [\"L_parotid\"],\n",
    "    \"Rt_Parotid\": [\"R_parotid\"]\n",
    "}\n",
    "\n",
    "for structure_name in structure_names:\n",
    "    for name_variation in structure_names[structure_name]:\n",
    "        df_dose_metrics.loc[df_dose_metrics.label==name_variation, \"label\"] = structure_name\n",
    "\n",
    "df_dose_metrics = df_dose_metrics[df_dose_metrics.label.isin(structure_names)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot dose metrics\n",
    "\n",
    "Now we can use the `seaborn` library to produce a box plot from these dose metrics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"D95\"\n",
    "sns.boxplot(data=df_dose_metrics, x=\"label\", y=metric, order=structure_names.keys())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output table of statistics\n",
    "\n",
    "And we can also output the dose metric statistics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dose_metrics[[\"label\"]+[metric]].groupby([\"label\"]).agg([\"mean\", \"std\", \"min\", \"max\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excerise\n",
    "\n",
    "Rerun the cells above, and try computing some different dose metrics. Here are a few things to try:\n",
    "\n",
    "- Try computing V dose metrics, add the `v_point` parameter in the\n",
    "`pydicer.analyse.compute_dose_metrics` function above.\n",
    "\n",
    "- Try plotting some different metrics.\n",
    "\n",
    "- Try plotting some metrics for some different labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydicer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "814af119db7f8f2860617be3dcd1d37c560587d11c65bd58c45b1679d3ee6ea4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
